from langchain_core.messages import HumanMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate, MessagesPlaceholder, ChatPromptTemplate, \
    FewShotChatMessagePromptTemplate
from langchain_openai import ChatOpenAI

from new_langchaing_practice.env_util import OPENAI_API_KEY, OPENAI_BASE_URL

llm = ChatOpenAI(
    model = 'gpt-4.1-nano',
    temperature = 0.8,
    api_key = OPENAI_API_KEY,
    base_url = OPENAI_BASE_URL,
    max_tokens = 200
)

# TODO: Let LLM answer the question with different style by adjusting the system message
# message = [
#     # ("system", "You are a smart assistant, and you answer question in a witty way."),
#     # ("system", "You are a serious assistant, and you answer question in an academic way."),
#     ("system", "You are an innocent cute baby, and you don't know too many things, but you answer question in a childish way."),
#     ("human", "Why is the sky blue?")
# ]
#
# resp = llm.invoke(message)
#
# print(resp.content)

# TODO: Use prompt template - variable placeholder
# prompt_template = PromptTemplate.from_template("Help me generate a story of {subject}.")
# chain = prompt_template | llm
#
# resp = chain.invoke({"subject" : "cute panda"})
#
# print(resp.content)

# TODO: FewShotPromptTemplate
# examples = [
#     {
#         "question": "ç©†ç½•é»˜å¾·Â·é˜¿é‡Œå’Œè‰¾ä¼¦Â·å›¾çµè°æ´»å¾—æ›´ä¹…ï¼Ÿ",
#         "answer": """
# æ˜¯å¦éœ€è¦åç»­é—®é¢˜ï¼šæ˜¯ã€‚
# åç»­é—®é¢˜ï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œå»ä¸–æ—¶å¤šå¤§ï¼Ÿ
# ä¸­é—´ç­”æ¡ˆï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œå»ä¸–æ—¶74å²ã€‚
# åç»­é—®é¢˜ï¼šè‰¾ä¼¦Â·å›¾çµå»ä¸–æ—¶å¤šå¤§ï¼Ÿ
# ä¸­é—´ç­”æ¡ˆï¼šè‰¾ä¼¦Â·å›¾çµå»ä¸–æ—¶41å²ã€‚
# æ‰€ä»¥æœ€ç»ˆç­”æ¡ˆæ˜¯ï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œ
# """,
#     },
#     {
#         "question": "ä¹”æ²»Â·åç››é¡¿çš„å¤–ç¥–çˆ¶æ˜¯è°ï¼Ÿ",
#         "answer": """
# æ˜¯å¦éœ€è¦åç»­é—®é¢˜ï¼šæ˜¯ã€‚
# åç»­é—®é¢˜ï¼šä¹”æ²»Â·åç››é¡¿çš„æ¯äº²æ˜¯è°ï¼Ÿ
# ä¸­é—´ç­”æ¡ˆï¼šä¹”æ²»Â·åç››é¡¿çš„æ¯äº²æ˜¯ç›ä¸½Â·é²å°”Â·åç››é¡¿ã€‚
# åç»­é—®é¢˜ï¼šç›ä¸½Â·é²å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯è°ï¼Ÿ
# ä¸­é—´ç­”æ¡ˆï¼šç›ä¸½Â·é²å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯çº¦ç‘Ÿå¤«Â·é²å°”ã€‚
# æ‰€ä»¥æœ€ç»ˆç­”æ¡ˆæ˜¯ï¼šçº¦ç‘Ÿå¤«Â·é²å°”
# """,
#     },
#     {
#         "question": "ã€Šå¤§ç™½é²¨ã€‹å’Œã€Š007ï¼šå¤§æˆ˜çš‡å®¶èµŒåœºã€‹çš„å¯¼æ¼”æ˜¯å¦æ¥è‡ªåŒä¸€ä¸ªå›½å®¶ï¼Ÿ",
#         "answer": """
# æ˜¯å¦éœ€è¦åç»­é—®é¢˜ï¼šæ˜¯ã€‚
# åç»­é—®é¢˜ï¼šã€Šå¤§ç™½é²¨ã€‹çš„å¯¼æ¼”æ˜¯è°ï¼Ÿ
# ä¸­é—´ç­”æ¡ˆï¼šã€Šå¤§ç™½é²¨ã€‹çš„å¯¼æ¼”æ˜¯å²è’‚æ–‡Â·æ–¯çš®å°”ä¼¯æ ¼ã€‚
# åç»­é—®é¢˜ï¼šå²è’‚æ–‡Â·æ–¯çš®å°”ä¼¯æ ¼æ¥è‡ªå“ªé‡Œï¼Ÿ
# ä¸­é—´ç­”æ¡ˆï¼šç¾å›½ã€‚
# åç»­é—®é¢˜ï¼šã€Š007ï¼šå¤§æˆ˜çš‡å®¶èµŒåœºã€‹çš„å¯¼æ¼”æ˜¯è°ï¼Ÿ
# ä¸­é—´ç­”æ¡ˆï¼šã€Š007ï¼šå¤§æˆ˜çš‡å®¶èµŒåœºã€‹çš„å¯¼æ¼”æ˜¯é©¬ä¸Â·åè´å°”ã€‚
# åç»­é—®é¢˜ï¼šé©¬ä¸Â·åè´å°”æ¥è‡ªå“ªé‡Œï¼Ÿ
# ä¸­é—´ç­”æ¡ˆï¼šæ–°è¥¿å…°ã€‚
# æ‰€ä»¥æœ€ç»ˆç­”æ¡ˆæ˜¯ï¼šå¦
# """,
#     },
# ]
# base_template = PromptTemplate.from_template("Question:{question}\n{answer}")
# final_template = FewShotPromptTemplate(
#     examples = examples,
#     example_prompt = base_template,
#     suffix = "Question: {input}",
#     input_variables = ["input"]
# )
#
# chain = final_template | llm
# resp = chain.invoke({"input" : "ä¸­å›½å†å²ä¸Šï¼Œéš‹æœå’Œç§¦æœå“ªä¸ªæŒç»­çš„æ—¶é—´æ¯”è¾ƒé•¿ï¼Ÿ"})
#
# print(resp)

# TODO: Use prompt template - message placeholder
# prompt_template = ChatPromptTemplate.from_messages([
#     ("system", "You are a basketball fan, and you favorite player is Kobe Bryant, you answer all the questions from your passion of basketball and Kobe Bryant."),
#     MessagesPlaceholder("input")
# ]
# )
# chain = prompt_template | llm
#
# resp = chain.invoke({"input" : [HumanMessage(content = "How to study math?")]})
#
# print(resp.content)

# TODO: ICL in chat template
examples = [
    {"input" : "2 ğŸ¦œ 2", "output" : "5"},
    {"input" : "3 ğŸ¦œ 2", "output" : "7"},
    {"input" : "4 ğŸ¦œ 6", "output" : "25"}
]

base_prompt = ChatPromptTemplate.from_messages(
    [
        ("human", "{input}"),
        ("ai", "{output}")
    ]
)

few_shot_prompt = FewShotChatMessagePromptTemplate(
    examples = examples,
    example_prompt = base_prompt
)

prompt_template = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a smart AI assistant. " "The following examples show how to interpret ğŸ¦œ."),
        # Must ask the model to learn from the examples
        few_shot_prompt,
        MessagesPlaceholder("msg")
    ]
)

chain = prompt_template | llm | StrOutputParser()

resp = chain.invoke({"msg" : [HumanMessage(content = "What is 5 ğŸ¦œ 8?")]})

print(resp)